{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.1.0-cp37-cp37m-win_amd64.whl (355.8 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.2.1-py3-none-any.whl (63 kB)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.28.1-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.11.3-cp37-cp37m-win_amd64.whl (1.0 MB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.14.0-py2.py3-none-any.whl (88 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.1.0.post20200127)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Downloading rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: absl-py, gast, termcolor\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121935 sha256=664325698779ce535f0855429c15704b9908fb241cd9a3b3926917c3c4686368\n",
      "  Stored in directory: c:\\users\\pablo\\appdata\\local\\pip\\cache\\wheels\\cc\\af\\1a\\498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7547 sha256=b4d9375441885bf16c1ab24cc23731c8e6be5a6848f1381ec88f4ab1e5730f3e\n",
      "  Stored in directory: c:\\users\\pablo\\appdata\\local\\pip\\cache\\wheels\\21\\7f\\02\\420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=04182b60fe1bc271f3736f53f680d82a11206581cb96d6d7bd5bae5a7100ee98\n",
      "  Stored in directory: c:\\users\\pablo\\appdata\\local\\pip\\cache\\wheels\\3f\\e3\\ec\\8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built absl-py gast termcolor\n",
      "Installing collected packages: opt-einsum, absl-py, protobuf, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, markdown, grpcio, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, astor, keras-applications, gast, tensorflow-estimator, scipy, termcolor, google-pasta, keras-preprocessing, tensorflow\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.2\n",
      "    Uninstalling scipy-1.3.2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\cluster\\\\hierarchy.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9d44a9367e0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TF_CPP_MIN_LOG_LEVEL'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"99\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a simple computation\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.Session()\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n",
    "# If you have gpu you can try this line to compute b with your GPU\n",
    "#with tf.device('/gpu:0'):    \n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "print(sess.run(c))\n",
    "\n",
    "# Runs the op.\n",
    "# Log information\n",
    "options = tf.RunOptions(output_partition_graphs=True)\n",
    "metadata = tf.RunMetadata()\n",
    "c_val = sess.run(c, options=options, run_metadata=metadata)\n",
    "\n",
    "print(metadata.partition_graphs)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "print('\\nShape de los datos de entrenamiento:', train.shape)\n",
    "train = train.select_dtypes(exclude=['object'])\n",
    "print(\"\")\n",
    "print('\\nDatos numericos dentro del DataSet:', train.shape)\n",
    "train.drop('Id',axis = 1, inplace = True)\n",
    "train.fillna(0,inplace=True)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test = test.select_dtypes(exclude=['object'])\n",
    "ID = test.Id\n",
    "test.fillna(0,inplace=True)\n",
    "test.drop('Id',axis = 1, inplace = True)\n",
    "\n",
    "print(\"\\nListado de opciones dentro del DataSet de entrenamiento:\",list(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(max_samples = 100, random_state = 42)\n",
    "clf.fit(train)\n",
    "y_noano = clf.predict(train)\n",
    "y_noano = pd.DataFrame(y_noano, columns = ['Top'])\n",
    "y_noano[y_noano['Top'] == 1].index.values\n",
    "\n",
    "train = train.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "print(\"Number of Outliers:\", y_noano[y_noano['Top'] == -1].shape[0])\n",
    "print(\"Number of rows without outliers:\", train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "col_train = list(train.columns)\n",
    "col_train_bis = list(train.columns)\n",
    "\n",
    "col_train_bis.remove('SalePrice')\n",
    "\n",
    "mat_train = np.matrix(train)\n",
    "mat_test  = np.matrix(test)\n",
    "mat_new = np.matrix(train.drop('SalePrice',axis = 1))\n",
    "mat_y = np.array(train.SalePrice).reshape((1314,1))\n",
    "\n",
    "prepro_y = MinMaxScaler()\n",
    "prepro_y.fit(mat_y)\n",
    "\n",
    "prepro = MinMaxScaler()\n",
    "prepro.fit(mat_train)\n",
    "\n",
    "prepro_test = MinMaxScaler()\n",
    "prepro_test.fit(mat_new)\n",
    "\n",
    "train = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\n",
    "test  = pd.DataFrame(prepro_test.transform(mat_test),columns = col_train_bis)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features\n",
    "COLUMNS = col_train\n",
    "FEATURES = col_train_bis\n",
    "LABEL = \"SalePrice\"\n",
    "\n",
    "# Columns for tensorflow\n",
    "feature_cols = [tf.contrib.layers.real_valued_column(k) for k in FEATURES]\n",
    "\n",
    "# Training set and Prediction set with the features to predict\n",
    "training_set = train[COLUMNS]\n",
    "prediction_set = train.SalePrice\n",
    "\n",
    "# Train and Test \n",
    "x_train, x_test, y_train, y_test = train_test_split(training_set[FEATURES] , prediction_set, test_size=0.33, random_state=42)\n",
    "y_train = pd.DataFrame(y_train, columns = [LABEL])\n",
    "training_set = pd.DataFrame(x_train, columns = FEATURES).merge(y_train, left_index = True, right_index = True)\n",
    "training_set.head()\n",
    "\n",
    "# Training for submission\n",
    "training_sub = training_set[col_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing but for the test set\n",
    "y_test = pd.DataFrame(y_test, columns = [LABEL])\n",
    "testing_set = pd.DataFrame(x_test, columns = FEATURES).merge(y_test, left_index = True, right_index = True)\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "regressor = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols, \n",
    "                                          activation_fn = tf.nn.relu, hidden_units=[200, 100, 50, 25, 12])#,\n",
    "                                         #optimizer = tf.train.GradientDescentOptimizer( learning_rate= 0.1 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of training\n",
    "training_set.reset_index(drop = True, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def input_fn(data_set, pred = False):\n",
    "    \n",
    "    if pred == False:\n",
    "        \n",
    "        feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n",
    "        labels = tf.constant(data_set[LABEL].values)\n",
    "        \n",
    "        return feature_cols, labels\n",
    "\n",
    "    if pred == True:\n",
    "        feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n",
    "        \n",
    "        return feature_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network Regressor with the training set which contain the data split by train test split\n",
    "regressor.fit(input_fn=lambda: input_fn(training_set), steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set created by train_test_split\n",
    "ev = regressor.evaluate(input_fn=lambda: input_fn(testing_set), steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the score on the testing set\n",
    "# 0.002X in average\n",
    "loss_score1 = ev[\"loss\"]\n",
    "print(\"Final Loss on the testing set: {0:f}\".format(loss_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y = regressor.predict(input_fn=lambda: input_fn(testing_set))\n",
    "predictions = list(itertools.islice(y, testing_set.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(prepro_y.inverse_transform(np.array(predictions).reshape(434,1)),columns = ['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reality = pd.DataFrame(prepro.inverse_transform(testing_set), columns = [COLUMNS]).SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('xtick', labelsize=30) \n",
    "matplotlib.rc('ytick', labelsize=30) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(50, 40))\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(predictions.values, reality.values, 'ro')\n",
    "plt.xlabel('Precio Predicho', fontsize = 30)\n",
    "plt.ylabel('Precio Real', fontsize = 30)\n",
    "plt.title('Prediccion vs Precio Real', fontsize = 30)\n",
    "ax.plot([reality.min(), reality.max()], [reality.min(), reality.max()], 'k--', lw=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = regressor.predict(input_fn=lambda: input_fn(test, pred = True))\n",
    "\n",
    "def to_submit(pred_y,name_out):\n",
    "    y_predict = list(itertools.islice(pred_y, test.shape[0]))\n",
    "    y_predict = pd.DataFrame(prepro_y.inverse_transform(np.array(y_predict).reshape(len(y_predict),1)), columns = ['SalePrice'])\n",
    "    y_predict = y_predict.join(ID)\n",
    "    y_predict.to_csv(name_out + '.csv',index=False)\n",
    "    \n",
    "to_submit(y_predict, \"submission_continuous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
